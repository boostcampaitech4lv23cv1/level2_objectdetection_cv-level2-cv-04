{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/configs/_khh_custom_configs/train'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "config file name: config4_baseline_dy.py\n",
      "save_dir /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0\n",
      "<<settings>>\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='open-mmlab://resnext101_64x4d'),\n",
      "        groups=64,\n",
      "        base_width=4),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=10,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        test_cfg=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        pretrained=None),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)))\n",
      "dataset_type = 'CocoDataset'\n",
      "root = '/opt/level2_objectdetection_cv-level2-cv-04/dataset/'\n",
      "classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',\n",
      "           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1024, 1024),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=10,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/train_fold0.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/val_fold0.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/test.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=10)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "seed = 42\n",
      "gpu_ids = [0]\n",
      "work_dir = '/opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0'\n",
      "device = 'cuda'\n",
      "\n",
      "2022-11-22 01:16:20,530 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-11-22 01:16:20,535 - mmdet - INFO - Start running, host: root@f63dd08cccbb, work_dir: /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0\n",
      "2022-11-22 01:16:20,535 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-22 01:16:20,535 - mmdet - INFO - workflow: [('train', 1)], max: 10 epochs\n",
      "2022-11-22 01:16:20,535 - mmdet - INFO - Checkpoints will be saved to /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0 by HardDiskBackend.\n",
      "2022-11-22 01:17:11,940 - mmdet - INFO - Epoch [1][50/392]\tlr: 1.978e-03, eta: 1:06:18, time: 1.028, data_time: 0.060, memory: 12153, loss_rpn_cls: 0.4239, loss_rpn_bbox: 0.0625, loss_cls: 0.9606, acc: 86.5664, loss_bbox: 0.1255, loss: 1.5724, grad_norm: 5.2073\n",
      "2022-11-22 01:18:00,539 - mmdet - INFO - Epoch [1][100/392]\tlr: 3.976e-03, eta: 1:03:39, time: 0.972, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.2155, loss_rpn_bbox: 0.0484, loss_cls: 0.3187, acc: 94.8770, loss_bbox: 0.1874, loss: 0.7701, grad_norm: 1.0847\n",
      "2022-11-22 01:18:49,176 - mmdet - INFO - Epoch [1][150/392]\tlr: 5.974e-03, eta: 1:02:15, time: 0.973, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.2068, loss_rpn_bbox: 0.0494, loss_cls: 0.2996, acc: 94.8855, loss_bbox: 0.1868, loss: 0.7426, grad_norm: 1.1107\n",
      "2022-11-22 01:19:37,794 - mmdet - INFO - Epoch [1][200/392]\tlr: 7.972e-03, eta: 1:01:08, time: 0.972, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1909, loss_rpn_bbox: 0.0436, loss_cls: 0.2837, acc: 95.0164, loss_bbox: 0.1855, loss: 0.7037, grad_norm: 0.8674\n",
      "2022-11-22 01:20:27,232 - mmdet - INFO - Epoch [1][250/392]\tlr: 9.970e-03, eta: 1:00:21, time: 0.989, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.2072, loss_rpn_bbox: 0.0524, loss_cls: 0.3191, acc: 94.2973, loss_bbox: 0.2102, loss: 0.7889, grad_norm: 1.1371\n",
      "2022-11-22 01:21:16,626 - mmdet - INFO - Epoch [1][300/392]\tlr: 1.197e-02, eta: 0:59:32, time: 0.988, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.2023, loss_rpn_bbox: 0.0559, loss_cls: 0.3384, acc: 93.8094, loss_bbox: 0.2308, loss: 0.8274, grad_norm: 1.2473\n",
      "2022-11-22 01:22:04,811 - mmdet - INFO - Epoch [1][350/392]\tlr: 1.397e-02, eta: 0:58:31, time: 0.964, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.2126, loss_rpn_bbox: 0.0551, loss_cls: 0.3359, acc: 93.9363, loss_bbox: 0.2244, loss: 0.8280, grad_norm: 1.3356\n",
      "2022-11-22 01:22:45,769 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2022-11-22 01:23:43,179 - mmdet - INFO - Epoch [2][50/392]\tlr: 1.764e-02, eta: 0:51:50, time: 1.021, data_time: 0.060, memory: 12153, loss_rpn_cls: 0.2024, loss_rpn_bbox: 0.0542, loss_cls: 0.3444, acc: 93.5594, loss_bbox: 0.2388, loss: 0.8397, grad_norm: 1.1994\n",
      "2022-11-22 01:24:31,620 - mmdet - INFO - Epoch [2][100/392]\tlr: 1.964e-02, eta: 0:51:31, time: 0.969, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1808, loss_rpn_bbox: 0.0494, loss_cls: 0.3287, acc: 93.6656, loss_bbox: 0.2337, loss: 0.7926, grad_norm: 1.0306\n",
      "2022-11-22 01:25:20,209 - mmdet - INFO - Epoch [2][150/392]\tlr: 2.000e-02, eta: 0:51:08, time: 0.972, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1807, loss_rpn_bbox: 0.0479, loss_cls: 0.3291, acc: 94.0840, loss_bbox: 0.2142, loss: 0.7719, grad_norm: 1.1942\n",
      "2022-11-22 01:26:09,139 - mmdet - INFO - Epoch [2][200/392]\tlr: 2.000e-02, eta: 0:50:42, time: 0.979, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1848, loss_rpn_bbox: 0.0490, loss_cls: 0.3364, acc: 93.6391, loss_bbox: 0.2310, loss: 0.8012, grad_norm: 0.9981\n",
      "2022-11-22 01:26:57,745 - mmdet - INFO - Epoch [2][250/392]\tlr: 2.000e-02, eta: 0:50:11, time: 0.972, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1941, loss_rpn_bbox: 0.0551, loss_cls: 0.3373, acc: 93.5402, loss_bbox: 0.2324, loss: 0.8189, grad_norm: 1.1317\n",
      "2022-11-22 01:27:46,395 - mmdet - INFO - Epoch [2][300/392]\tlr: 2.000e-02, eta: 0:49:38, time: 0.973, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1844, loss_rpn_bbox: 0.0516, loss_cls: 0.3122, acc: 93.9758, loss_bbox: 0.2117, loss: 0.7599, grad_norm: 0.8744\n",
      "2022-11-22 01:28:35,410 - mmdet - INFO - Epoch [2][350/392]\tlr: 2.000e-02, eta: 0:49:04, time: 0.980, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1877, loss_rpn_bbox: 0.0555, loss_cls: 0.3296, acc: 93.4277, loss_bbox: 0.2299, loss: 0.8026, grad_norm: 0.9210\n",
      "2022-11-22 01:29:16,737 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
      "2022-11-22 01:30:14,124 - mmdet - INFO - Epoch [3][50/392]\tlr: 2.000e-02, eta: 0:45:32, time: 1.020, data_time: 0.059, memory: 12153, loss_rpn_cls: 0.1813, loss_rpn_bbox: 0.0523, loss_cls: 0.3096, acc: 93.9727, loss_bbox: 0.2064, loss: 0.7495, grad_norm: 1.0331\n",
      "2022-11-22 01:31:02,503 - mmdet - INFO - Epoch [3][100/392]\tlr: 2.000e-02, eta: 0:45:02, time: 0.968, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1867, loss_rpn_bbox: 0.0555, loss_cls: 0.2987, acc: 94.1449, loss_bbox: 0.2007, loss: 0.7417, grad_norm: 1.0022\n",
      "2022-11-22 01:31:50,885 - mmdet - INFO - Epoch [3][150/392]\tlr: 2.000e-02, eta: 0:44:30, time: 0.968, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1738, loss_rpn_bbox: 0.0502, loss_cls: 0.3283, acc: 93.4195, loss_bbox: 0.2249, loss: 0.7771, grad_norm: 0.9625\n",
      "2022-11-22 01:32:39,007 - mmdet - INFO - Epoch [3][200/392]\tlr: 2.000e-02, eta: 0:43:55, time: 0.962, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1667, loss_rpn_bbox: 0.0481, loss_cls: 0.3168, acc: 93.5945, loss_bbox: 0.2194, loss: 0.7508, grad_norm: 0.9345\n",
      "2022-11-22 01:33:27,290 - mmdet - INFO - Epoch [3][250/392]\tlr: 2.000e-02, eta: 0:43:20, time: 0.966, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1758, loss_rpn_bbox: 0.0500, loss_cls: 0.3350, acc: 93.2961, loss_bbox: 0.2292, loss: 0.7900, grad_norm: 1.0621\n",
      "2022-11-22 01:34:15,706 - mmdet - INFO - Epoch [3][300/392]\tlr: 2.000e-02, eta: 0:42:44, time: 0.968, data_time: 0.012, memory: 12153, loss_rpn_cls: 0.1543, loss_rpn_bbox: 0.0436, loss_cls: 0.3218, acc: 93.4512, loss_bbox: 0.2225, loss: 0.7423, grad_norm: 0.9271\n",
      "2022-11-22 01:35:04,074 - mmdet - INFO - Epoch [3][350/392]\tlr: 2.000e-02, eta: 0:42:06, time: 0.967, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1550, loss_rpn_bbox: 0.0474, loss_cls: 0.3077, acc: 93.4828, loss_bbox: 0.2185, loss: 0.7287, grad_norm: 0.8285\n",
      "2022-11-22 01:35:45,047 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "2022-11-22 01:36:42,427 - mmdet - INFO - Epoch [4][50/392]\tlr: 2.000e-02, eta: 0:39:32, time: 1.020, data_time: 0.060, memory: 12154, loss_rpn_cls: 0.1740, loss_rpn_bbox: 0.0474, loss_cls: 0.3128, acc: 93.7008, loss_bbox: 0.2115, loss: 0.7458, grad_norm: 0.8831\n",
      "2022-11-22 01:37:30,906 - mmdet - INFO - Epoch [4][100/392]\tlr: 2.000e-02, eta: 0:38:57, time: 0.970, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1643, loss_rpn_bbox: 0.0476, loss_cls: 0.3117, acc: 93.4680, loss_bbox: 0.2172, loss: 0.7408, grad_norm: 0.8752\n",
      "2022-11-22 01:38:19,843 - mmdet - INFO - Epoch [4][150/392]\tlr: 2.000e-02, eta: 0:38:22, time: 0.979, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1495, loss_rpn_bbox: 0.0481, loss_cls: 0.3160, acc: 93.3586, loss_bbox: 0.2233, loss: 0.7369, grad_norm: 0.9024\n",
      "2022-11-22 01:39:07,977 - mmdet - INFO - Epoch [4][200/392]\tlr: 2.000e-02, eta: 0:37:44, time: 0.963, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1614, loss_rpn_bbox: 0.0480, loss_cls: 0.3150, acc: 93.4098, loss_bbox: 0.2178, loss: 0.7422, grad_norm: 0.9457\n",
      "2022-11-22 01:39:55,892 - mmdet - INFO - Epoch [4][250/392]\tlr: 2.000e-02, eta: 0:37:06, time: 0.958, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1513, loss_rpn_bbox: 0.0506, loss_cls: 0.3092, acc: 93.4453, loss_bbox: 0.2168, loss: 0.7279, grad_norm: 0.8199\n",
      "2022-11-22 01:40:43,947 - mmdet - INFO - Epoch [4][300/392]\tlr: 2.000e-02, eta: 0:36:27, time: 0.961, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1466, loss_rpn_bbox: 0.0447, loss_cls: 0.3012, acc: 93.8191, loss_bbox: 0.2051, loss: 0.6976, grad_norm: 0.8881\n",
      "2022-11-22 01:41:31,952 - mmdet - INFO - Epoch [4][350/392]\tlr: 2.000e-02, eta: 0:35:47, time: 0.960, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1633, loss_rpn_bbox: 0.0505, loss_cls: 0.3170, acc: 93.1434, loss_bbox: 0.2261, loss: 0.7568, grad_norm: 0.9322\n",
      "2022-11-22 01:42:12,881 - mmdet - INFO - Saving checkpoint at 4 epochs\n",
      "2022-11-22 01:43:10,073 - mmdet - INFO - Epoch [5][50/392]\tlr: 2.000e-02, eta: 0:33:40, time: 1.017, data_time: 0.060, memory: 12154, loss_rpn_cls: 0.1324, loss_rpn_bbox: 0.0418, loss_cls: 0.2929, acc: 93.7484, loss_bbox: 0.2062, loss: 0.6733, grad_norm: 0.8646\n",
      "2022-11-22 01:43:58,282 - mmdet - INFO - Epoch [5][100/392]\tlr: 2.000e-02, eta: 0:33:02, time: 0.964, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1668, loss_rpn_bbox: 0.0555, loss_cls: 0.3328, acc: 92.8895, loss_bbox: 0.2278, loss: 0.7830, grad_norm: 1.0125\n",
      "2022-11-22 01:44:46,616 - mmdet - INFO - Epoch [5][150/392]\tlr: 2.000e-02, eta: 0:32:23, time: 0.967, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1490, loss_rpn_bbox: 0.0459, loss_cls: 0.3259, acc: 92.8520, loss_bbox: 0.2343, loss: 0.7551, grad_norm: 0.9358\n",
      "2022-11-22 01:45:34,846 - mmdet - INFO - Epoch [5][200/392]\tlr: 2.000e-02, eta: 0:31:44, time: 0.965, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1427, loss_rpn_bbox: 0.0451, loss_cls: 0.2986, acc: 93.6789, loss_bbox: 0.2089, loss: 0.6954, grad_norm: 0.9112\n",
      "2022-11-22 01:46:23,651 - mmdet - INFO - Epoch [5][250/392]\tlr: 2.000e-02, eta: 0:31:05, time: 0.976, data_time: 0.013, memory: 12154, loss_rpn_cls: 0.1627, loss_rpn_bbox: 0.0540, loss_cls: 0.3119, acc: 93.4297, loss_bbox: 0.2128, loss: 0.7415, grad_norm: 1.0763\n",
      "2022-11-22 01:47:12,790 - mmdet - INFO - Epoch [5][300/392]\tlr: 2.000e-02, eta: 0:30:26, time: 0.983, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1500, loss_rpn_bbox: 0.0453, loss_cls: 0.3047, acc: 93.4309, loss_bbox: 0.2134, loss: 0.7134, grad_norm: 0.9488\n",
      "2022-11-22 01:48:01,425 - mmdet - INFO - Epoch [5][350/392]\tlr: 2.000e-02, eta: 0:29:46, time: 0.973, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1465, loss_rpn_bbox: 0.0450, loss_cls: 0.2945, acc: 93.5543, loss_bbox: 0.2071, loss: 0.6932, grad_norm: 0.8462\n",
      "2022-11-22 01:48:41,683 - mmdet - INFO - Saving checkpoint at 5 epochs\n",
      "2022-11-22 01:49:39,272 - mmdet - INFO - Epoch [6][50/392]\tlr: 2.000e-02, eta: 0:27:54, time: 1.024, data_time: 0.059, memory: 12154, loss_rpn_cls: 0.1429, loss_rpn_bbox: 0.0456, loss_cls: 0.3053, acc: 93.1895, loss_bbox: 0.2193, loss: 0.7131, grad_norm: 0.9128\n",
      "2022-11-22 01:50:28,385 - mmdet - INFO - Epoch [6][100/392]\tlr: 2.000e-02, eta: 0:27:15, time: 0.982, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1374, loss_rpn_bbox: 0.0447, loss_cls: 0.3139, acc: 93.2242, loss_bbox: 0.2191, loss: 0.7151, grad_norm: 0.9235\n",
      "2022-11-22 01:51:17,749 - mmdet - INFO - Epoch [6][150/392]\tlr: 2.000e-02, eta: 0:26:36, time: 0.987, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1485, loss_rpn_bbox: 0.0498, loss_cls: 0.2847, acc: 93.9301, loss_bbox: 0.1913, loss: 0.6743, grad_norm: 0.9193\n",
      "2022-11-22 01:52:06,587 - mmdet - INFO - Epoch [6][200/392]\tlr: 2.000e-02, eta: 0:25:56, time: 0.977, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1370, loss_rpn_bbox: 0.0453, loss_cls: 0.2911, acc: 93.6383, loss_bbox: 0.2042, loss: 0.6777, grad_norm: 0.9357\n",
      "2022-11-22 01:52:55,187 - mmdet - INFO - Epoch [6][250/392]\tlr: 2.000e-02, eta: 0:25:15, time: 0.972, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1627, loss_rpn_bbox: 0.0532, loss_cls: 0.3297, acc: 92.8215, loss_bbox: 0.2297, loss: 0.7753, grad_norm: 1.1008\n",
      "2022-11-22 01:53:43,796 - mmdet - INFO - Epoch [6][300/392]\tlr: 2.000e-02, eta: 0:24:34, time: 0.972, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1398, loss_rpn_bbox: 0.0463, loss_cls: 0.3107, acc: 93.0227, loss_bbox: 0.2205, loss: 0.7173, grad_norm: 0.8952\n",
      "2022-11-22 01:54:32,244 - mmdet - INFO - Epoch [6][350/392]\tlr: 2.000e-02, eta: 0:23:52, time: 0.969, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1285, loss_rpn_bbox: 0.0430, loss_cls: 0.3142, acc: 93.0617, loss_bbox: 0.2247, loss: 0.7104, grad_norm: 0.9244\n",
      "2022-11-22 01:55:12,848 - mmdet - INFO - Saving checkpoint at 6 epochs\n",
      "2022-11-22 01:56:10,529 - mmdet - INFO - Epoch [7][50/392]\tlr: 2.000e-02, eta: 0:22:11, time: 1.026, data_time: 0.060, memory: 12154, loss_rpn_cls: 0.1279, loss_rpn_bbox: 0.0451, loss_cls: 0.2985, acc: 93.3207, loss_bbox: 0.2085, loss: 0.6800, grad_norm: 0.8930\n",
      "2022-11-22 01:56:59,236 - mmdet - INFO - Epoch [7][100/392]\tlr: 2.000e-02, eta: 0:21:30, time: 0.974, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1299, loss_rpn_bbox: 0.0421, loss_cls: 0.2948, acc: 93.3750, loss_bbox: 0.2079, loss: 0.6747, grad_norm: 0.9466\n",
      "2022-11-22 01:57:47,325 - mmdet - INFO - Epoch [7][150/392]\tlr: 2.000e-02, eta: 0:20:48, time: 0.962, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1350, loss_rpn_bbox: 0.0453, loss_cls: 0.2807, acc: 93.8012, loss_bbox: 0.1908, loss: 0.6519, grad_norm: 0.9643\n",
      "2022-11-22 01:58:35,125 - mmdet - INFO - Epoch [7][200/392]\tlr: 2.000e-02, eta: 0:20:06, time: 0.956, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1428, loss_rpn_bbox: 0.0484, loss_cls: 0.3130, acc: 92.9816, loss_bbox: 0.2203, loss: 0.7245, grad_norm: 0.9728\n",
      "2022-11-22 01:59:23,512 - mmdet - INFO - Epoch [7][250/392]\tlr: 2.000e-02, eta: 0:19:24, time: 0.968, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1546, loss_rpn_bbox: 0.0484, loss_cls: 0.3199, acc: 92.9250, loss_bbox: 0.2230, loss: 0.7458, grad_norm: 1.0750\n",
      "2022-11-22 02:00:12,027 - mmdet - INFO - Epoch [7][300/392]\tlr: 2.000e-02, eta: 0:18:42, time: 0.970, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1444, loss_rpn_bbox: 0.0490, loss_cls: 0.3172, acc: 92.7363, loss_bbox: 0.2286, loss: 0.7392, grad_norm: 0.9495\n",
      "2022-11-22 02:01:00,601 - mmdet - INFO - Epoch [7][350/392]\tlr: 2.000e-02, eta: 0:18:00, time: 0.971, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1499, loss_rpn_bbox: 0.0497, loss_cls: 0.3190, acc: 92.8812, loss_bbox: 0.2253, loss: 0.7439, grad_norm: 1.0628\n",
      "2022-11-22 02:01:41,307 - mmdet - INFO - Saving checkpoint at 7 epochs\n",
      "2022-11-22 02:02:37,997 - mmdet - INFO - Epoch [8][50/392]\tlr: 2.000e-02, eta: 0:16:26, time: 1.006, data_time: 0.060, memory: 12154, loss_rpn_cls: 0.1403, loss_rpn_bbox: 0.0510, loss_cls: 0.3209, acc: 92.6500, loss_bbox: 0.2279, loss: 0.7402, grad_norm: 0.9424\n",
      "2022-11-22 02:03:25,905 - mmdet - INFO - Epoch [8][100/392]\tlr: 2.000e-02, eta: 0:15:43, time: 0.958, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1377, loss_rpn_bbox: 0.0482, loss_cls: 0.3314, acc: 92.3477, loss_bbox: 0.2392, loss: 0.7565, grad_norm: 1.0310\n",
      "2022-11-22 02:04:13,822 - mmdet - INFO - Epoch [8][150/392]\tlr: 2.000e-02, eta: 0:15:01, time: 0.958, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1278, loss_rpn_bbox: 0.0418, loss_cls: 0.2790, acc: 93.7070, loss_bbox: 0.1935, loss: 0.6421, grad_norm: 0.9102\n",
      "2022-11-22 02:05:01,864 - mmdet - INFO - Epoch [8][200/392]\tlr: 2.000e-02, eta: 0:14:18, time: 0.961, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1322, loss_rpn_bbox: 0.0459, loss_cls: 0.3009, acc: 93.1418, loss_bbox: 0.2139, loss: 0.6930, grad_norm: 0.9473\n",
      "2022-11-22 02:05:50,529 - mmdet - INFO - Epoch [8][250/392]\tlr: 2.000e-02, eta: 0:13:36, time: 0.973, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1258, loss_rpn_bbox: 0.0404, loss_cls: 0.3024, acc: 93.1555, loss_bbox: 0.2116, loss: 0.6803, grad_norm: 1.0000\n",
      "2022-11-22 02:06:38,641 - mmdet - INFO - Epoch [8][300/392]\tlr: 2.000e-02, eta: 0:12:53, time: 0.962, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1209, loss_rpn_bbox: 0.0444, loss_cls: 0.2937, acc: 93.1941, loss_bbox: 0.2096, loss: 0.6686, grad_norm: 0.8832\n",
      "2022-11-22 02:07:26,664 - mmdet - INFO - Epoch [8][350/392]\tlr: 2.000e-02, eta: 0:12:10, time: 0.960, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1513, loss_rpn_bbox: 0.0513, loss_cls: 0.3154, acc: 92.8898, loss_bbox: 0.2169, loss: 0.7349, grad_norm: 1.0283\n",
      "2022-11-22 02:08:07,152 - mmdet - INFO - Saving checkpoint at 8 epochs\n",
      "2022-11-22 02:09:04,737 - mmdet - INFO - Epoch [9][50/392]\tlr: 2.000e-03, eta: 0:10:42, time: 1.024, data_time: 0.060, memory: 12154, loss_rpn_cls: 0.1294, loss_rpn_bbox: 0.0469, loss_cls: 0.3084, acc: 92.5645, loss_bbox: 0.2258, loss: 0.7106, grad_norm: 0.8574\n",
      "2022-11-22 02:09:52,455 - mmdet - INFO - Epoch [9][100/392]\tlr: 2.000e-03, eta: 0:09:59, time: 0.954, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1195, loss_rpn_bbox: 0.0425, loss_cls: 0.2919, acc: 93.1227, loss_bbox: 0.2098, loss: 0.6637, grad_norm: 0.7711\n",
      "2022-11-22 02:10:41,125 - mmdet - INFO - Epoch [9][150/392]\tlr: 2.000e-03, eta: 0:09:16, time: 0.973, data_time: 0.013, memory: 12154, loss_rpn_cls: 0.1155, loss_rpn_bbox: 0.0415, loss_cls: 0.3006, acc: 92.9113, loss_bbox: 0.2186, loss: 0.6762, grad_norm: 0.7885\n",
      "2022-11-22 02:11:29,351 - mmdet - INFO - Epoch [9][200/392]\tlr: 2.000e-03, eta: 0:08:33, time: 0.965, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1187, loss_rpn_bbox: 0.0431, loss_cls: 0.2981, acc: 92.8570, loss_bbox: 0.2163, loss: 0.6761, grad_norm: 0.8052\n",
      "2022-11-22 02:12:17,868 - mmdet - INFO - Epoch [9][250/392]\tlr: 2.000e-03, eta: 0:07:49, time: 0.970, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1153, loss_rpn_bbox: 0.0447, loss_cls: 0.2973, acc: 92.9203, loss_bbox: 0.2172, loss: 0.6745, grad_norm: 0.8338\n",
      "2022-11-22 02:13:06,123 - mmdet - INFO - Epoch [9][300/392]\tlr: 2.000e-03, eta: 0:07:06, time: 0.965, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1316, loss_rpn_bbox: 0.0478, loss_cls: 0.3117, acc: 92.5586, loss_bbox: 0.2224, loss: 0.7136, grad_norm: 0.8950\n",
      "2022-11-22 02:13:54,815 - mmdet - INFO - Epoch [9][350/392]\tlr: 2.000e-03, eta: 0:06:23, time: 0.974, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1219, loss_rpn_bbox: 0.0417, loss_cls: 0.2925, acc: 93.1070, loss_bbox: 0.2076, loss: 0.6637, grad_norm: 0.8758\n",
      "2022-11-22 02:14:35,987 - mmdet - INFO - Saving checkpoint at 9 epochs\n",
      "2022-11-22 02:15:34,083 - mmdet - INFO - Epoch [10][50/392]\tlr: 2.000e-03, eta: 0:04:59, time: 1.034, data_time: 0.061, memory: 12154, loss_rpn_cls: 0.1268, loss_rpn_bbox: 0.0457, loss_cls: 0.3213, acc: 92.2535, loss_bbox: 0.2348, loss: 0.7287, grad_norm: 0.9138\n",
      "2022-11-22 02:16:22,391 - mmdet - INFO - Epoch [10][100/392]\tlr: 2.000e-03, eta: 0:04:15, time: 0.966, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1197, loss_rpn_bbox: 0.0458, loss_cls: 0.3156, acc: 92.4074, loss_bbox: 0.2286, loss: 0.7097, grad_norm: 0.9180\n",
      "2022-11-22 02:17:10,949 - mmdet - INFO - Epoch [10][150/392]\tlr: 2.000e-03, eta: 0:03:32, time: 0.971, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1207, loss_rpn_bbox: 0.0433, loss_cls: 0.2968, acc: 92.8484, loss_bbox: 0.2146, loss: 0.6754, grad_norm: 0.9027\n",
      "2022-11-22 02:17:59,136 - mmdet - INFO - Epoch [10][200/392]\tlr: 2.000e-03, eta: 0:02:48, time: 0.964, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1078, loss_rpn_bbox: 0.0387, loss_cls: 0.2946, acc: 92.9867, loss_bbox: 0.2107, loss: 0.6518, grad_norm: 0.8620\n",
      "2022-11-22 02:18:47,334 - mmdet - INFO - Epoch [10][250/392]\tlr: 2.000e-03, eta: 0:02:04, time: 0.964, data_time: 0.012, memory: 12154, loss_rpn_cls: 0.1206, loss_rpn_bbox: 0.0447, loss_cls: 0.2904, acc: 93.0758, loss_bbox: 0.2113, loss: 0.6670, grad_norm: 0.9094\n",
      "2022-11-22 02:19:35,989 - mmdet - INFO - Epoch [10][300/392]\tlr: 2.000e-03, eta: 0:01:21, time: 0.973, data_time: 0.013, memory: 12154, loss_rpn_cls: 0.1169, loss_rpn_bbox: 0.0435, loss_cls: 0.2850, acc: 93.2992, loss_bbox: 0.2030, loss: 0.6483, grad_norm: 0.9008\n",
      "2022-11-22 02:20:24,235 - mmdet - INFO - Epoch [10][350/392]\tlr: 2.000e-03, eta: 0:00:37, time: 0.965, data_time: 0.013, memory: 12154, loss_rpn_cls: 0.1113, loss_rpn_bbox: 0.0412, loss_cls: 0.2992, acc: 92.7473, loss_bbox: 0.2181, loss: 0.6698, grad_norm: 0.8865\n",
      "2022-11-22 02:21:05,623 - mmdet - INFO - Saving checkpoint at 10 epochs\n"
     ]
    }
   ],
   "source": [
    "!python config_train.py --fold_num 0 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "config file name: config4_baseline_dy.py\n",
      "save_dir /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold1\n",
      "<<settings>>\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='open-mmlab://resnext101_64x4d'),\n",
      "        groups=64,\n",
      "        base_width=4),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=10,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        test_cfg=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        pretrained=None),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)))\n",
      "dataset_type = 'CocoDataset'\n",
      "root = '/opt/level2_objectdetection_cv-level2-cv-04/dataset/'\n",
      "classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',\n",
      "           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1024, 1024),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/train_fold1.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/val_fold1.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/test.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=10)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "seed = 42\n",
      "gpu_ids = [0]\n",
      "work_dir = '/opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold1'\n",
      "device = 'cuda'\n",
      "\n",
      "2022-11-22 02:21:22,957 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-11-22 02:21:22,961 - mmdet - INFO - Start running, host: root@f63dd08cccbb, work_dir: /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold1\n",
      "2022-11-22 02:21:22,962 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-22 02:21:22,962 - mmdet - INFO - workflow: [('train', 1)], max: 10 epochs\n",
      "2022-11-22 02:21:22,962 - mmdet - INFO - Checkpoints will be saved to /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold1 by HardDiskBackend.\n"
     ]
    }
   ],
   "source": [
    "!python config_train.py --fold_num 1 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 2 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 3 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 4 --config_file_name config4_baseline_dy.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b94c6de4bce9a87a354a5fa9998691adc0532adddb9d4140f5ba941d00b01fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
