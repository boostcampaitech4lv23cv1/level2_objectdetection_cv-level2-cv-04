{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/configs/_khh_custom_configs/train'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "config file name: config4_baseline_dy.py\n",
      "save_dir /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0\n",
      "<<settings>>\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='open-mmlab://resnext101_64x4d'),\n",
      "        groups=64,\n",
      "        base_width=4),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=10,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        test_cfg=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        pretrained=None),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)))\n",
      "dataset_type = 'CocoDataset'\n",
      "root = '/opt/level2_objectdetection_cv-level2-cv-04/dataset/'\n",
      "classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',\n",
      "           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1024, 1024),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/train_fold0.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/val_fold0.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),\n",
      "        img_prefix='/opt/level2_objectdetection_cv-level2-cv-04/dataset/',\n",
      "        ann_file=\n",
      "        '/opt/level2_objectdetection_cv-level2-cv-04/dataset/test.json',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=10)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "seed = 42\n",
      "gpu_ids = [0]\n",
      "work_dir = '/opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0'\n",
      "device = 'cuda'\n",
      "\n",
      "2022-11-21 11:28:21,294 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-11-21 11:28:21,299 - mmdet - INFO - Start running, host: root@f63dd08cccbb, work_dir: /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0\n",
      "2022-11-21 11:28:21,299 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-21 11:28:21,299 - mmdet - INFO - workflow: [('train', 1)], max: 10 epochs\n",
      "2022-11-21 11:28:21,299 - mmdet - INFO - Checkpoints will be saved to /opt/level2_objectdetection_cv-level2-cv-04/baseline/mmdetection/work_dirs/config4_baseline_dy__fold0 by HardDiskBackend.\n",
      "2022-11-21 11:28:51,881 - mmdet - INFO - Epoch [1][50/979]\tlr: 1.978e-03, eta: 1:39:16, time: 0.612, data_time: 0.052, memory: 5470, loss_rpn_cls: 0.3957, loss_rpn_bbox: 0.0491, loss_cls: 0.9573, acc: 86.5928, loss_bbox: 0.0930, loss: 1.4950, grad_norm: 5.7611\n",
      "2022-11-21 11:29:19,099 - mmdet - INFO - Epoch [1][100/979]\tlr: 3.976e-03, eta: 1:33:20, time: 0.544, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1996, loss_rpn_bbox: 0.0457, loss_cls: 0.3294, acc: 95.1299, loss_bbox: 0.1805, loss: 0.7551, grad_norm: 1.6170\n",
      "2022-11-21 11:29:46,671 - mmdet - INFO - Epoch [1][150/979]\tlr: 5.974e-03, eta: 1:31:26, time: 0.551, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1902, loss_rpn_bbox: 0.0463, loss_cls: 0.2991, acc: 94.9805, loss_bbox: 0.1867, loss: 0.7223, grad_norm: 1.2925\n",
      "2022-11-21 11:30:13,861 - mmdet - INFO - Epoch [1][200/979]\tlr: 7.972e-03, eta: 1:29:57, time: 0.544, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2165, loss_rpn_bbox: 0.0530, loss_cls: 0.2972, acc: 94.9062, loss_bbox: 0.1856, loss: 0.7523, grad_norm: 1.4999\n",
      "2022-11-21 11:30:41,224 - mmdet - INFO - Epoch [1][250/979]\tlr: 9.970e-03, eta: 1:28:59, time: 0.547, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2108, loss_rpn_bbox: 0.0585, loss_cls: 0.3428, acc: 94.0811, loss_bbox: 0.2214, loss: 0.8334, grad_norm: 1.6426\n",
      "2022-11-21 11:31:08,651 - mmdet - INFO - Epoch [1][300/979]\tlr: 1.197e-02, eta: 1:28:13, time: 0.549, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2063, loss_rpn_bbox: 0.0543, loss_cls: 0.3156, acc: 94.3867, loss_bbox: 0.2073, loss: 0.7835, grad_norm: 1.5427\n",
      "2022-11-21 11:31:36,190 - mmdet - INFO - Epoch [1][350/979]\tlr: 1.397e-02, eta: 1:27:36, time: 0.551, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2336, loss_rpn_bbox: 0.0654, loss_cls: 0.3489, acc: 94.4072, loss_bbox: 0.2027, loss: 0.8507, grad_norm: 1.8077\n",
      "2022-11-21 11:32:04,356 - mmdet - INFO - Epoch [1][400/979]\tlr: 1.596e-02, eta: 1:27:16, time: 0.563, data_time: 0.007, memory: 5470, loss_rpn_cls: 0.2139, loss_rpn_bbox: 0.0597, loss_cls: 0.3538, acc: 94.1670, loss_bbox: 0.2161, loss: 0.8435, grad_norm: 1.8407\n",
      "2022-11-21 11:32:31,554 - mmdet - INFO - Epoch [1][450/979]\tlr: 1.796e-02, eta: 1:26:34, time: 0.544, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2317, loss_rpn_bbox: 0.0657, loss_cls: 0.3580, acc: 93.8877, loss_bbox: 0.2230, loss: 0.8783, grad_norm: 1.4435\n",
      "2022-11-21 11:32:58,896 - mmdet - INFO - Epoch [1][500/979]\tlr: 1.996e-02, eta: 1:25:57, time: 0.547, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2205, loss_rpn_bbox: 0.0625, loss_cls: 0.3313, acc: 93.7217, loss_bbox: 0.2263, loss: 0.8407, grad_norm: 1.0856\n",
      "2022-11-21 11:33:26,421 - mmdet - INFO - Epoch [1][550/979]\tlr: 2.000e-02, eta: 1:25:25, time: 0.551, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1910, loss_rpn_bbox: 0.0543, loss_cls: 0.3406, acc: 93.7891, loss_bbox: 0.2304, loss: 0.8162, grad_norm: 1.1865\n",
      "2022-11-21 11:33:53,651 - mmdet - INFO - Epoch [1][600/979]\tlr: 2.000e-02, eta: 1:24:50, time: 0.545, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1940, loss_rpn_bbox: 0.0540, loss_cls: 0.3621, acc: 93.0371, loss_bbox: 0.2596, loss: 0.8698, grad_norm: 1.0672\n",
      "2022-11-21 11:34:21,313 - mmdet - INFO - Epoch [1][650/979]\tlr: 2.000e-02, eta: 1:24:22, time: 0.553, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2285, loss_rpn_bbox: 0.0591, loss_cls: 0.3670, acc: 93.4727, loss_bbox: 0.2319, loss: 0.8864, grad_norm: 1.3501\n",
      "2022-11-21 11:34:48,560 - mmdet - INFO - Epoch [1][700/979]\tlr: 2.000e-02, eta: 1:23:48, time: 0.545, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.2046, loss_rpn_bbox: 0.0547, loss_cls: 0.3619, acc: 93.3047, loss_bbox: 0.2425, loss: 0.8638, grad_norm: 1.0589\n",
      "2022-11-21 11:35:15,476 - mmdet - INFO - Epoch [1][750/979]\tlr: 2.000e-02, eta: 1:23:12, time: 0.538, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1658, loss_rpn_bbox: 0.0436, loss_cls: 0.3019, acc: 94.3066, loss_bbox: 0.2097, loss: 0.7211, grad_norm: 0.8739\n",
      "2022-11-21 11:35:42,302 - mmdet - INFO - Epoch [1][800/979]\tlr: 2.000e-02, eta: 1:22:35, time: 0.537, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1985, loss_rpn_bbox: 0.0541, loss_cls: 0.3404, acc: 93.6436, loss_bbox: 0.2271, loss: 0.8201, grad_norm: 1.0120\n",
      "2022-11-21 11:36:09,536 - mmdet - INFO - Epoch [1][850/979]\tlr: 2.000e-02, eta: 1:22:04, time: 0.545, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1924, loss_rpn_bbox: 0.0551, loss_cls: 0.3352, acc: 93.3545, loss_bbox: 0.2305, loss: 0.8131, grad_norm: 0.9610\n",
      "2022-11-21 11:36:36,845 - mmdet - INFO - Epoch [1][900/979]\tlr: 2.000e-02, eta: 1:21:34, time: 0.546, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1877, loss_rpn_bbox: 0.0563, loss_cls: 0.3378, acc: 93.4492, loss_bbox: 0.2303, loss: 0.8121, grad_norm: 0.9869\n",
      "2022-11-21 11:37:04,131 - mmdet - INFO - Epoch [1][950/979]\tlr: 2.000e-02, eta: 1:21:04, time: 0.546, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1690, loss_rpn_bbox: 0.0434, loss_cls: 0.3087, acc: 94.2588, loss_bbox: 0.2020, loss: 0.7231, grad_norm: 0.9710\n",
      "2022-11-21 11:37:20,493 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2022-11-21 11:37:52,165 - mmdet - INFO - Epoch [2][50/979]\tlr: 2.000e-02, eta: 1:18:21, time: 0.589, data_time: 0.049, memory: 5470, loss_rpn_cls: 0.1655, loss_rpn_bbox: 0.0437, loss_cls: 0.3094, acc: 93.8164, loss_bbox: 0.2146, loss: 0.7332, grad_norm: 0.9252\n",
      "2022-11-21 11:38:19,463 - mmdet - INFO - Epoch [2][100/979]\tlr: 2.000e-02, eta: 1:17:58, time: 0.546, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1539, loss_rpn_bbox: 0.0405, loss_cls: 0.2983, acc: 94.1064, loss_bbox: 0.2033, loss: 0.6960, grad_norm: 0.8947\n",
      "2022-11-21 11:38:46,741 - mmdet - INFO - Epoch [2][150/979]\tlr: 2.000e-02, eta: 1:17:35, time: 0.546, data_time: 0.006, memory: 5470, loss_rpn_cls: 0.1771, loss_rpn_bbox: 0.0487, loss_cls: 0.3163, acc: 93.6963, loss_bbox: 0.2211, loss: 0.7632, grad_norm: 0.8785\n"
     ]
    }
   ],
   "source": [
    "!python config_train.py --fold_num 0 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 1 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 2 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 3 --config_file_name config4_baseline_dy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config_train.py --fold_num 4 --config_file_name config4_baseline_dy.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b94c6de4bce9a87a354a5fa9998691adc0532adddb9d4140f5ba941d00b01fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
